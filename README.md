# Hyperion: An Algorithmic Trading Framework Forged in Obsession

![Version](https://img.shields.io/badge/version-3.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.8+-brightgreen.svg)
![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)
![Trading](https://img.shields.io/badge/trading-algorithmic-gold.svg)
![AI](https://img.shields.io/badge/AI-enabled-purple.svg)
![MLOps](https://img.shields.io/badge/MLOps-integrated-orange.svg)

> "Hyperion is not just code. It's the answer to a challenge that completely captivated me. It's the tool I wish I had when I started."

(This is still a beta version - not all parts of the bot are working perfectly yet, but as more days pass, I realize it will never be as perfect as I dream, so I decided to show what's been developed. In the coming days, I'll fix the remaining errors and implement all the features. Thanks for reading, I hope to be up to the challenge)

## ğŸš¨ CRITICAL WARNING - READ THIS FIRST

<table>
<tr>
<td>
<h3>âš ï¸ EXTREME FINANCIAL RISK</h3>

**Hyperion is a RESEARCH and LEARNING tool, NOT a money-making machine.**

- ğŸ”® **Backtests do NOT guarantee future returns**
- ğŸŒªï¸ **The real market is chaotic and unpredictable**
- ğŸ’° **NEVER invest money you can't afford to lose**
- âš–ï¸ **Use it under your COMPLETE responsibility**
- ğŸ§ª **ALWAYS practice in paper trading first**

**Algorithmic trading requires deep knowledge, risk management, and understanding that losses are part of the game.**
</td>
</tr>
</table>

## ğŸ’« The Story Behind Hyperion

Hello, I'm the creator of Hyperion. Giovanni, but I prefer to be called Ganador (Winner). Let me tell you a story.

I always dreamed of creating a trading bot that operated autonomously, an intelligent machine capable of navigating the turbulent seas of the market. When I started, my naivety made me think it would be an easy task. I believed that in a couple of weekends I would have something working.

**How wrong I was.**

I soon came face to face with reality: building a cutting-edge bot, starting from scratch and alone, is a colossal challenge. I immersed myself in an ocean of research papers, model architectures, and preprocessing techniques, and each new layer of knowledge revealed ten more that I didn't know.

When looking for help, I realized that the landscape of public and free trading bots was bleak. Most were too simple, black boxes without flexibility, or directly useless. I felt immense frustration. How could someone, with more desire than experience, start in this world?

It was in that moment of frustration and challenge that **Hyperion was born**. I decided that if the tool I needed didn't exist, I would build it myself.

This project is the result of countless hours of work, trial and error, small failures and great victories. My most sincere hope is that Hyperion saves you part of that difficult path and gives you the power so that you too can transform your ideas into real strategies.

## ğŸš€ Quick Start

### ğŸ¯ Complete Setup (5 minutes)
```bash
# 1. Start the professional system (RECOMMENDED)
pip install -r requirements.txt
python main.py

# 2. Access the professional interface directly
python main_professional.py

# 3. Validate the modular structure
python test_modular_structure.py
```

## ğŸ—ï¸ The Hyperion Pipeline: Anatomy of an Idea

Hyperion is designed as a **modular and automated pipeline** that transforms raw market data into robust and validated trading strategies. The entire process is controlled from a single configuration file (`config.json`), simplifying a workflow that would otherwise be extremely complex.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Config    â”‚ -> â”‚    Data     â”‚ -> â”‚Preprocessor â”‚ -> â”‚   Model     â”‚
â”‚ (config.json)â”‚    â”‚ Downloader  â”‚    â”‚& Features   â”‚    â”‚  Trainer    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                  â”‚
                                                                  v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    MLOps    â”‚ <- â”‚ Backtester  â”‚ <- â”‚  Ensemble   â”‚ <- â”‚ Hyperopt    â”‚
â”‚  Tracking   â”‚    â”‚& Validation â”‚    â”‚ Creation    â”‚    â”‚ (FLAML)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ§  Stage 1: Configuration (config.json)
**The Brain of the Operation**: Here you define everything: the cryptocurrency pair (e.g., BTC/USDT), the time interval (1h, 4h, 1d), start and end dates, and most importantly: the list of models you want to test and the optimizer configuration.

### ğŸ“Š Stage 2: Data Acquisition (hyperion3/data/downloader.py)
Hyperion connects to data sources and downloads the OHLCV (Open, High, Low, Close, Volume) price history for the asset you specified. Data is saved locally for quick access and reuse.

### âš™ï¸ Stage 3: Preprocessing and Feature Engineering
**Cleaning and Preparation**: Raw data is cleaned of missing values and prepared for analysis.

**Intelligence Creation**: Here's where the magic happens! Hyperion doesn't just use price. It generates an arsenal of **more than 100 features** to give models deep market context:

- **ğŸ“ˆ Momentum Indicators**: RSI, Stochastic, MACD, Williams %R
- **ğŸ“Š Trend Indicators**: Moving Averages (SMA, EMA), Bollinger Bands, ADX, Ichimoku Cloud, Vortex
- **ğŸ’¨ Volatility Indicators**: ATR (Average True Range), Keltner Channels
- **ğŸ“Š Volume Analysis**: On-Balance Volume (OBV)
- **ğŸ•¯ï¸ Japanese Candlestick Patterns**: Doji, Engulfing, Hammer, etc.
- **ğŸ­ Data Augmentation**: To avoid overfitting, synthetic variations of the data are created

### ğŸ”¬ Stage 4: Advanced Hyperparameter Optimization
**The Search for Perfection**: Hyperion features a sophisticated multi-engine optimization system that automatically discovers optimal parameters for **50+ models** across multiple categories.

#### ğŸ¯ **Optimization Engines**:
- **ğŸ”¥ Optuna**: Bayesian optimization with TPE (Tree-structured Parzen Estimator) sampler for intelligent parameter space exploration
- **âš¡ FLAML**: Microsoft's AutoML framework for rapid optimization with resource constraints
- **ğŸ§  Scikit-learn**: Traditional GridSearch/RandomSearch for comprehensive parameter coverage
- **ğŸ² TPOT**: Genetic programming for automated pipeline optimization

#### ğŸ“Š **Supported Model Categories** (50+ models):

**ğŸŒ³ Scikit-learn Models (35+ algorithms)**:
- *Tree-based*: RandomForest, GradientBoosting, ExtraTrees, AdaBoost, Bagging, HistGradientBoosting
- *Linear Models*: Ridge, Lasso, ElasticNet, BayesianRidge, ARDRegression, HuberRegressor, TheilSenRegressor, RANSACRegressor
- *SVM Variants*: SVR, NuSVR, LinearSVR with RBF/Polynomial/Linear kernels
- *Neural Networks*: MLPRegressor with customizable architectures
- *Advanced*: GaussianProcess, KernelRidge, QuantileRegressor, TweedieRegressor, PoissonRegressor, GammaRegressor

**âš¡ Gradient Boosting Libraries**:
- **XGBoost**: Full parameter space optimization with GPU acceleration support
- **LightGBM**: High-performance boosting with memory-efficient optimization
- **CatBoost**: Categorical feature handling with automatic GPU detection

**ğŸ§  Deep Learning Models**:
- **PyTorch**: SimpleMLP, DeepMLP, LSTM networks with architecture optimization
- **Transformers**: Temporal Fusion Transformer (TFT), PatchTST with attention mechanism tuning
- **Custom**: Neural architecture search for optimal layer configurations

**ğŸ® Reinforcement Learning Agents**:
- **SAC** (Soft Actor-Critic): Continuous action spaces with entropy regularization
- **TD3** (Twin Delayed DDPG): Policy gradient methods with noise injection
- **Rainbow DQN**: Multi-improvement DQN with distributional learning

#### ğŸš€ **Advanced Optimization Features**:
```python
# Comprehensive optimization example
from utils.hyperopt import HyperparameterOptimizer

# Initialize with GPU configuration
optimizer = HyperparameterOptimizer(
    console=console,
    gpu_config={
        'xgboost_params': {'tree_method': 'gpu_hist'},
        'lightgbm_params': {'device': 'gpu'},
        'catboost_params': {'task_type': 'GPU'}
    }
)

# Optimize all 50+ models
results = optimizer.optimize_all_models(
    X_train, y_train, X_val, y_val, 
    n_trials=100  # Bayesian optimization trials
)

# Category-specific optimization
sklearn_best = optimizer.optimize_sklearn_models(X_train, y_train, X_val, y_val, n_trials=50)
rl_best = optimizer.optimize_rl_agents(X_train, y_train, X_val, y_val, n_trials=30)
```

#### ğŸ¨ **Smart Parameter Spaces**:
- **Dynamic ranges**: Parameters automatically adjusted based on dataset characteristics
- **Model-specific constraints**: Each algorithm has tailored parameter boundaries
- **Multi-objective**: Simultaneous optimization for accuracy, speed, and memory usage
- **Early stopping**: Intelligent trial pruning with Optuna's median stopping
- **Cross-validation**: Integrated CV for robust hyperparameter validation

### ğŸ¤ Stage 5: Ensemble Creation
**The Wisdom of the Crowd**: Instead of relying on a single "genius", Hyperion can combine the predictions of your best models in an ensemble. This often leads to more stable and robust decisions.

### ğŸ§ª Stage 6: Rigorous Backtesting
**The Trial by Fire**: The Backtester simulates how your strategy would have performed in the past, trade by trade. It provides you with critical metrics like Total Return, Sharpe Ratio, Maximum Drawdown, and hit rate.

### ğŸ“ˆ Stage 7: Analysis and MLOps
**Reproducibility and Transparency**: Every detail of your experiment is automatically recorded with MLflow. This allows you to compare different approaches and return to any point in your research without getting lost.

## ğŸ¤– The Model Arsenal: A Complete Spectrum of Intelligence

Hyperion integrates an exceptionally diverse model library, allowing you to approach the problem from multiple angles. All models are instantiated through `hyperion3/models/model_factory.py`.

### ğŸ“Š 1. Classical and Statistical Models
- **Prophet**: Developed by Facebook, excellent for capturing seasonalities and trends robustly

### ğŸŒ³ 2. Machine Learning Models (Tree-Based)
The backbone of modern data science. They are fast, interpretable, and very powerful:

- **ğŸš€ LightGBM**: The fastest option. Uses extremely efficient leaf-wise growth
- **ğŸ† XGBoost**: The gold standard. Famous for its performance and anti-overfitting regularization
- **ğŸ¯ CatBoost**: Specially designed to handle data efficiently, very robust
- **ğŸŒ² RandomForest and ExtraTrees**: Ensembles of multiple trees to improve robustness

### ğŸ§  3. Deep Learning Models for Time Series
Specifically designed to capture complex temporal dependencies:

- **ğŸ“ˆ N-BEATS**: Decomposes the time series into interpretable components
- **âš¡ N-HITS**: Evolution of N-BEATS with better efficiency and frequency spectrum
- **ğŸ”¥ TFT (Temporal Fusion Transformer)**: Fuses different types of data with attention mechanisms
- **ğŸ’ PatchTST (Transformer)**: The crown jewel! Based on Google's Transformer architecture, processes the time series in "patches" to capture short and long-term relationships

### ğŸ® 4. Reinforcement Learning (RL)
**The most radical paradigm shift**. Instead of predicting the future, agents learn to act to maximize rewards:

- **ğŸ­ SAC (Soft Actor-Critic)**: Modern, efficient and very stable algorithm
- **ğŸ¯ TD3 (Twin Delayed DDPG)**: Robust, designed to mitigate value overestimation
- **ğŸŒˆ Rainbow DQN**: Improvement of the classic DQN that combines multiple techniques

**How does RL work?** The agent is the "trader". It observes the market and decides actions (buy/sell/hold). If it wins, it receives positive reward. After thousands of simulations, it learns a policy to maximize profits. It's the closest thing to teaching an AI to "think" like a trader.

## âœ¨ Professional Interface

Hyperion3 features a **complete professional interface**:

### ğŸ¯ **Main Menu Features**
- **ğŸ¤– MODELS**: Train individual models by category (sklearn, ensemble, pytorch, automl)
- **ğŸ¯ HYPERPARAMETERS**: Automatic and manual hyperparameter optimization
- **ğŸ­ ENSEMBLES**: Create and manage ensembles (voting, weighted, stacking, bagging)
- **ğŸ“Š ANALYSIS**: Complete analysis of results and performance metrics
- **âš™ï¸ CONFIGURATION**: System configuration management
- **ğŸ“ˆ MONITORING**: Real-time system monitoring

### ğŸ”§ **Modular Training Options**
```bash
# Train specific models
s1, s2, s3...    # sklearn models (Random Forest, Gradient Boosting, etc.)
e1, e2, e3...    # ensemble models (XGBoost, LightGBM, CatBoost)
p1, p2, p3...    # pytorch models (MLP, LSTM, Transformer)
a1, a2...        # automl models (FLAML, Optuna)

# Train by category
sklearn, ensemble, pytorch, automl

# Train all models
all
```

## ğŸš€ Installation

### Quick Installation
```bash
pip install -r requirements.txt
```

### ğŸ For Apple Silicon users
```bash
./install_mac.sh
```

### ğŸ“‹ Requirements
- **Python 3.8+**
- **Unix OS** (Linux or macOS recommended)
- **Optional**: GPU with CUDA for deep learning models

See [docs/INSTALLATION.md](docs/INSTALLATION.md) for detailed instructions.

## ğŸ—ï¸ Project Architecture

The code is organized in modular packages:

- **`hyperion3/models/`** â€“ transformers and RL agents
- **`hyperion3/training/`** â€“ training loops and callbacks
- **`hyperion3/evaluations/`** â€“ backtester and financial metrics
- **`hyperion3/optimization/`** â€“ AutoML utilities with FLAML
- **`hyperion3/data/`** â€“ downloaders, preprocessing and feature engineering
- **`scripts/deployment/`** â€“ live trading engine and monitoring
- **`scripts/`** â€“ auxiliary commands for training and testing
- **`docs/`** â€“ additional documentation

### ğŸ¨ Professional Features
- **ğŸ¨ Rich UI**: Beautiful console interface with Rich library
- **ğŸ”§ Modular Design**: Clean separation in utils/ modules
- **âš¡ Performance**: Optimized for Apple Silicon (MPS) and CUDA
- **ğŸ’¾ Auto-Save**: Automatic saving of models, results and configurations
- **ğŸ“Š Analytics**: Integrated analysis and comparison tools

### ğŸ“ˆ Advanced Features
- **ğŸ“Š Real-time data** with Binance API
- **ğŸ§ª Advanced backtesting** with multiple strategies
- **âš ï¸ Risk management** and portfolio optimization
- **ğŸ”¬ MLOps integration** with experiment tracking
- **â° Multi-timeframe analysis** and prediction

## ğŸ“Š Dataset Management

Raw datasets reside in `data/`. Use the provided preprocessing scripts to generate features and augmentations. The `DataConfig` class controls symbols, lookback windows, and additional data sources like sentiment, orderbook, or on-chain metrics.

See [`docs/DATA_MANAGEMENT.md`](docs/DATA_MANAGEMENT.md) for a complete tutorial.

## ğŸ“š Documentation

Additional guides available in the `docs/` directory:

- [`BACKTESTER.md`](docs/BACKTESTER.md) â€“ advanced backtesting engine
- [`EXPERIMENTS.md`](docs/EXPERIMENTS.md) â€“ running configurable experiments
- [`VALIDATORS.md`](docs/VALIDATORS.md) â€“ cross-validation helpers
- [`INSTALLATION.md`](docs/INSTALLATION.md) â€“ detailed installation instructions
- [`DEVELOPMENT_GUIDE.md`](docs/DEVELOPMENT_GUIDE.md) â€“ development guide

## ğŸ¤ Join the Journey

Hyperion is a **living and constantly evolving project**. If you're passionate about this world, your help is welcome. You can contribute:

- ğŸ› **Reporting bugs** via Issues
- ğŸ’¡ **Suggesting new features** 
- ğŸ”§ **Adding your own code** via Pull Requests
- ğŸ“– **Improving documentation**
- ğŸ§ª **Sharing experiment results**

The project structure is modular, which facilitates adding new models, metrics, or data processors.

### ğŸ› ï¸ How to Contribute
1. Fork the repository
2. Create a branch for your feature (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

Make sure all tests pass before submitting.

## ğŸ“œ License

This project is published under the terms of the Apache 2.0 License. See [`LICENSE`](LICENSE) for more details.

---

## ğŸŒŸ Acknowledgments

Thanks to the open source community and all the researchers whose work has made Hyperion possible.

**âœ¨ Ready to transform your ideas into real strategies? Start your journey with Hyperion today!**

```bash
git clone https://github.com/your-username/hyperion.git
cd hyperion
pip install -r requirements.txt
python main.py
```

*Thanks for reading to the end. This is my first project and I hope this and the following ones I work on can be useful.*

---

**ğŸ“– Documentation available in multiple languages:**
- ğŸ‡ºğŸ‡¸ [English](README.md) (current)
- ğŸ‡ªğŸ‡¸ [EspaÃ±ol](README_es.md)
